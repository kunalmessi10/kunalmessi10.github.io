<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Kunal Pratap Singh</title>
  
  <meta name="author" content="Kunal Pratap Singh">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Kunal Pratap Singh</name>
              </p>
                <p>I am an incoming Ph.D. student at the <a href="https://vilab.epfl.ch/">VILAB</a> at <a href="https://www.epfl.ch/en/">EPFL</a> this fall, where I'm advised by Prof. <a href="https://vilab.epfl.ch/zamir/">Amir Zamir</a>. Before grad school, I spent two amazing years in the <a href="https://prior.allenai.org/people">PRIOR</a> team at the Allen Institute for AI (AI2). I work on Computer Vision, Embodied AI, and Reinforcement Learning. 
              </p>
              
              <p>
                Previously I was a research assistant at the <a href="https://gistvision.github.io/">Computer Vision Lab</a> at GIST working with <a href="https://ppolon.github.io/">Prof. Jonghyun Choi</a>. Even earlier, I finished my undergraduate studies at the <a href="https://iitr.ac.in/">Indian Institute of Technology, Roorkee</a>, during which I also interned at the <a href="http://val.serc.iisc.ernet.in/valweb/index.html">Video Analytics Lab, Indian Institute of Science</a> with <a href="http://cds.iisc.ac.in/faculty/venky/">Prof. R. Venkatesh Babu</a>.
              </p>
             
              <p style="text-align:center">
                <a href="mailto:ksingh@ee.iitr.ac.in">Email</a> &nbsp/&nbsp
                <a href="images/Kunal_Pratap_CV_final.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=IYACEjgAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.semanticscholar.org/author/Kunal-Pratap-Singh/153866008">Semantic Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/kunalpratapiitr">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/kunalmessi10/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="headshot_1_png.png"><img style="width:100%;max-width:100%" alt="profile photo" src="kunal_pic_resize.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I am interested in building actionable representations that enable embodied agents to physically reason about their environments and perform tasks for and alongside humans.     
              </p>
            </td>
          </tr>
        </tbody></table>
        
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr onmouseout="nerfie_stop()" onmouseover="nerfie_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfie_image'>
                </div>

                <img src='images/graph_loss_v3.png' width="180">
              </div>
              <script type="text/javascript">
                function nerfie_start() {
                  document.getElementById('nerfie_image').style.opacity = "1";
                }

                function nerfie_stop() {
                  document.getElementById('nerfie_image').style.opacity = "0";
                }
                nerfie_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Scene Graph Contrastive Learning for Embodied Navigation</papertitle>
              <br>
              <strong>Kunal Pratap Singh</strong>,
              <a href="https://scholar.google.de/citations?user=YuRVs2oAAAAJ&hl=en">Jordi Salvador</a>,
              <a href="https://lucaweihs.github.io/">Luca Weihs</a>,
              <a href="https://anikem.github.io/">Aniruddha Kembhavi </a>
              
              
              <br>
              ICCV, 2023
              <br>
              <a href="https://kunalmessi10.github.io/">Paper</a>
              <p></p>
              <p>We propose the Scene Graph Contrastive Loss, an auxiliary objective that encourages the agent's belief to align its representation with a rich graphical encoding of its environments. We show results on Object Navigation, Multi-Object Navigation and ArmPointNavigation.</p>
            </td>
          </tr>
          
            <tr onmouseout="nerfie_stop()" onmouseover="nerfie_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfie_image'>
                </div>

                <img src='images/ask4help_teaser_png.png' width="180">
              </div>
              <script type="text/javascript">
                function nerfie_start() {
                  document.getElementById('nerfie_image').style.opacity = "1";
                }

                function nerfie_stop() {
                  document.getElementById('nerfie_image').style.opacity = "0";
                }
                nerfie_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Ask4Help : Learning to Leverage an Expert for Embodied Tasks</papertitle>
              <br>
              
              <strong>Kunal Pratap Singh</strong>,
              <a href="https://lucaweihs.github.io/">Luca Weihs</a>,
              <a href="https://scholar.google.com/citations?user=89Knd5YAAAAJ&hl=en">Alvaro Herrasti</a>,
              <a href="https://ppolon.github.io">Jonghyun Choi</a>,
              <a href="https://anikem.github.io/">Aniruddha Kembhavi </a>,
              <a href="https://roozbehm.info/">Roozbeh Mottaghi</a>
              
              <br>
              NeurIPS, 2022
              <br>
              <a href="https://arxiv.org/pdf/2211.09960v1.pdf">Paper</a> | <a href="https://github.com/allenai/ask4help">Code</a>
              <p></p>
              <p> We propose Ask4Help, a framework that endows embodied agents with the ability to request expert help. We applying this framework to existing off-the-shelf Embodied-AI models and improve task performance on Object Navigation and Room Rearrangement.</p>
            </td>
          </tr> 
          
          
          <tr onmouseout="nerfie_stop()" onmouseover="nerfie_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfie_image'>
                </div>

               <img src='images/alfred_fig.png' width="160">
  
              </div>
              <script type="text/javascript">
                function nerfie_start() {
                  document.getElementById('nerfie_image').style.opacity = "1";
                }

                function nerfie_stop() {
                  document.getElementById('nerfie_image').style.opacity = "0";
                }
                nerfie_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Factorizing Policy and Perception for Interactive Instruction Following</papertitle>
              <br>
              
              <strong>Kunal Pratap Singh*</strong>,
              <a href="https://www.linkedin.com/in/suvaansh-bhambri-1784bab7/">Suvaansh Bhambri*</a>,
              <a href="https://bhkim94.github.io/">Byeonghwi Kim*</a>,
              <a href="http://roozbehm.info/">Roozbeh Mottaghi</a>,
              <a href="https://ppolon.github.io">Jonghyun Choi</a>
              <br>
              ICCV, 2021
              <br>
              <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Singh_Factorizing_Perception_and_Policy_for_Interactive_Instruction_Following_ICCV_2021_paper.pdf">Paper</a> | <a href="https://github.com/gistvision/moca/">Code</a>
              <br>
              <p> We factorize the policy and perception into separate streams to train effective instruction following agents on the ALFRED benchmark.
              </p>
              Also presented at <a href="https://askforalfred.com/EVAL/">Embodied Vision, Actions and Language</a> Workshop, ECCV 2020 and <a href="https://embodied-ai.org/cvpr2021">Embodied-AI workshop</a>, CVPR 2021.               
              <p></p>
             
            </td>
          </tr>           
          <tr onmouseout="nerfie_stop()" onmouseover="nerfie_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfie_image'>
                </div>

                <img src='images/ours_normal-1.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfie_start() {
                  document.getElementById('nerfie_image').style.opacity = "1";
                }

                function nerfie_stop() {
                  document.getElementById('nerfie_image').style.opacity = "0";
                }
                nerfie_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Learning Architecture for Binary Networks</papertitle>
              <br>
              
              <strong>Kunal Pratap Singh*</strong>,
              <a href="https://github.com/killawhale2">Dahyun Kim*</a>,
              <a href="https://ppolon.github.io">Jonghyun Choi</a>
              <br>
              ECCV, 2020 
              <br>
              <a href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123570562.pdf">Paper</a> | <a href="https://github.com/gistvision/bnas/">Code</a>
              <p></p>
              <p> We develop the first architecture search method for binary neural networks. We propose a new search space and cell design, and discover architectures that outperform floating point backbones.
              </p>
            </td>
          </tr> 

          <tr onmouseout="flare_stop()" onmouseover="flare_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='flare_image'>
                  <img src='images/iccp_fig2.png' width="160"></div>
                <img src='images/iccp_fig2.png' width="160">
              </div>
              <script type="text/javascript">
                function flare_start() {
                  document.getElementById('flare_image').style.opacity = "1";
                }

                function flare_stop() {
                  document.getElementById('flare_image').style.opacity = "0";
                }
                flare_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>A Fast, Scalable, and Reliable Deghosting Method for Extreme Exposure Fusion</papertitle>
              <br>
              <a href="https://sites.google.com/view/kramprabhakar/home?authuser=0">K. Ram Prabhakar*</a>,
              <a href="https://sites.google.com/view/rajatswebspace/home">Rajat Arora*</a>,
              Adhitya Swaminathan,
              <strong>Kunal Pratap Singh</strong>,
              <a href="http://val.serc.iisc.ernet.in/valweb/people.html">R. Venkatesh Babu</a>
              <br>
              ICCP, 2019
              <br>
              <a href="http://val.serc.iisc.ernet.in/ICCP19/files/EF_iccp19.pdf">Paper</a> | <a href="https://github.com/rajat95/Deep-Deghosting-HDR">Code</a>  
              <br>
              <p></p>
              <p>
                 Proposed a flexible Deep Learning based approach for exposure fusion and HDR Imaging from arbitrary number of exposure bracketed shots.
              </p>
            </td>
          </tr> 

        
 
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <br>
                This template is stolen from <a href="https://jonbarron.info/">here</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
